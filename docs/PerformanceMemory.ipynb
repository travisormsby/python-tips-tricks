{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-_2hR6yZLIl"
      },
      "source": [
        "# Performance and Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VogyfkL7ZLIq"
      },
      "source": [
        "When you begin to use Python regularly in your work, you'll start noticing bottlenecks in your code. Some workflows may run at lightning speed, while others take hours of processing time to complete, or even crash.\n",
        "\n",
        "Avoiding bloat is invaluable as you move toward using code for automation, bigger data, and working with APIs. Code efficiency means:\n",
        "- Less chance of a slowdown or crash: the dreaded MemoryError.\n",
        "- Quicker response time and fewer bottlenecks for the larger workflow.\n",
        "- Better scaling.\n",
        "- Efficient code is often (but not always!) cleaner and more readable.\n",
        "\n",
        "Let's look at some ways you can reduce bloat in your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2BFe18pZLIr"
      },
      "source": [
        "## Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_P41638ZLIw"
      },
      "source": [
        "tl;dr\n",
        "<br>Access and store only what you need, no more.\n",
        "- __Storage__: avoid a list where you could use a tuple\n",
        "- __Membership look-up__: avoid a list/tuple where you could use a set/dictionary\n",
        "- __Iteration__: avoid a sequence where you could use generator\n",
        "- __Calculation__: avoid a loop where you could use vectorized math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "Yu9yyeYPZLIx"
      },
      "source": [
        "### Storage: lists vs. tuples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "IqMfe4DUZLIx"
      },
      "source": [
        "If you have a collection of values, your first thought may be to store them in a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "oVG7ozejZLIy"
      },
      "outputs": [],
      "source": [
        "data_list = [17999712, 2015, 'Hawkins Road', 'Linden ', 'NC', 28356]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "vPGEfGsKZLIz"
      },
      "source": [
        "Lists are nice because they are very flexible. You can change the values in the list, including appending and removing values. But that flexibility comes at a cost. Lists are less efficient than tuples. For example, they use more memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "kzw4GFpYZLI1",
        "outputId": "e0138832-159c-4fed-9f17-69e93ebd8899",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "104\n",
            "88\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "data_tuple = (17999712, 2015, 'Hawkins Road', 'Linden ', 'NC', 28356)\n",
        "\n",
        "print(sys.getsizeof(data_list))\n",
        "print(sys.getsizeof(data_tuple))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "SncGVcIiZLI3"
      },
      "source": [
        "If you aren't going to be changing the values in a collection, use a tuple instead of a list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "YdLJhldrZLI3"
      },
      "source": [
        "### Membership look-up: lists vs. sets and dictionaries"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, when you want to see if an element _already exists_ in a collection of elements, use a set or dictionary to store that collection if possible.\n",
        "\n",
        "Lists and tuples require **sequential look-up** to see if an element is a member of the collection. That means that on average, they have to make n/2 comparisons for a collection of length n. Meanwhile, hash tables and dictionaries **map keys to values**. That means no matter how big the collection is, the set only ever has to check 1 value.\n",
        "\n",
        "Fun fact: A set can use a hash table for look-ups, similar to a dictionary, because every element in a set is unique."
      ],
      "metadata": {
        "id": "x9vIWqKJESyn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- List and tuple look-up goes at the speed of _O(n): linear time_. Time increases linearly with the number of elements.\n",
        "    - With lists, Python scans the entire list until it finds the match (or reaches the end).\n",
        "    - Worst case: it has to look at every element.\n",
        "\n",
        "- Set and dictionary look-up goes at the speed of _O(1): constant time_. Takes the same time no matter the size of the data.\n",
        "    - Sets are built on hash tables. Python computes the hash of the element and jumps straight to where it should be stored."
      ],
      "metadata": {
        "id": "0VCAv3ZUxOXY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "oVdOgTk1ZLI4"
      },
      "source": [
        "The example below shows that a set is over 1000x faster than a list in calculating the first 100,000 values of [Recaman's sequence](https://oeis.org/search?q=recaman&language=english&go=Search)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "WpTGEYfyZLI5"
      },
      "outputs": [],
      "source": [
        "def recaman_check(cur, i, visited):\n",
        "    return (cur - i) < 0 or (cur - i) in visited\n",
        "\n",
        "def recaman_list(n: int) -> list[int]:\n",
        "    \"\"\"\n",
        "    return a list of the first n numbers of the Recaman series\n",
        "    \"\"\"\n",
        "\n",
        "    visited_list = [0]\n",
        "    current = 0\n",
        "    for i in range(1, n):\n",
        "        if recaman_check(current, i, visited_list):\n",
        "            current += i\n",
        "        else:\n",
        "            current -= i\n",
        "        visited_list.append(current)\n",
        "    return visited_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "nZDnh3iWZLI6",
        "outputId": "abbebfc7-0557-46f3-dc5f-a3ae2ee46830",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33.6 s ± 1.62 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "recaman_list(100000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "vvLVZGkKZLI6"
      },
      "outputs": [],
      "source": [
        "def recaman_set(n: int) -> list[int]:\n",
        "    visited_set = {0}\n",
        "    current = 0\n",
        "    for i in range(1, 100_000):\n",
        "        if recaman_check(current, i, visited_set):\n",
        "            current += i\n",
        "        else:\n",
        "            current -= i\n",
        "        visited_set.add(current)\n",
        "    return visited_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "wFaIMHJlZLI7",
        "outputId": "ca3f5f2d-1a70-428e-a8ba-90ab4015b9b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23.7 ms ± 1.15 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "recaman_set(100000)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you add an element to a set...\n",
        "1. Python calls the element’s __hash__() method to get a hash value (an integer);\n",
        "1. That hash value determines where the element will be stored in the set's internal structure; and\n",
        "1. When checking if an element is in the set, Python uses the hash to quickly find it."
      ],
      "metadata": {
        "id": "cmwf-LTNLk2o"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "da9ChQAwZLI7"
      },
      "source": [
        "### Iteration: sequences vs. generators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "AES7kqT2ZLI8"
      },
      "source": [
        "Regular functions and comprehensions typically create a container type like a list or a dictionary to store the data that results from the function’s intended computation. All this data is stored in memory at the same time.\n",
        "\n",
        "In contrast, iterators keep only one data item in memory at a time, generating the next items on demand or lazily.\n",
        "\n",
        "With iterators and generators, you don’t need to store all the data in your compter’s memory at the same time.\n",
        "\n",
        "Iterators and generators also allow you to completely decouple iteration from processing individual items. They let you connect multiple data processing stages to create memory-efficient data processing pipelines."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When working with dataframes, we often use functions to operate on data, but generators can be more memory-efficient and faster for certain tasks—especially when you're processing rows one at a time or streaming large datasets."
      ],
      "metadata": {
        "id": "59BbxRiDuYVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s say you have a huge CSV that you want to process row by row, applying some logic to each row. Using a generator here helps avoid loading the entire DataFrame into memory."
      ],
      "metadata": {
        "id": "td-sjAbZuk_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def process_all_rows(filepath):\n",
        "    df = pd.read_csv(filepath)\n",
        "    for _, row in df.iterrows():\n",
        "        process_row(row)\n",
        "\n",
        "def process_row(row):\n",
        "    # Imagine some expensive operation here\n",
        "    if row[\"value\"] > 1000:\n",
        "        print(row[\"name\"], row[\"value\"])"
      ],
      "metadata": {
        "id": "vi6duXe_ujwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the CSV is huge, this can eat up memory. Instead, what if we process data in chunks or rows lazily?"
      ],
      "metadata": {
        "id": "w06e15kmuppV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def row_generator(filepath, chunksize=1000):\n",
        "    for chunk in pd.read_csv(filepath, chunksize=chunksize):\n",
        "        for _, row in chunk.iterrows():\n",
        "            yield row\n",
        "\n",
        "def process_large_file(filepath):\n",
        "    for row in row_generator(filepath):\n",
        "        if row[\"value\"] > 1000:\n",
        "            print(row[\"name\"], row[\"value\"])"
      ],
      "metadata": {
        "id": "chy2TtgYuzUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When to prefer a generator:\n",
        "- You're dealing with very large datasets that would be cumbersome to load into memory.\n",
        "- You want to start processing before loading everything.\n",
        "- You're doing line-by-line processing, not vectorized Pandas ops.\n",
        "- Streaming data or preprocessing before database insertions."
      ],
      "metadata": {
        "id": "xgvGsS52u4G6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculation: loop versus intersection"
      ],
      "metadata": {
        "id": "0vGWLh-mBnAY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HhMLyvGZLI8"
      },
      "source": [
        "## Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vwEgO0TZLI8"
      },
      "source": [
        "tl;dr\n",
        "<br>Make time for performance checks.\n",
        "\n",
        "Resources:\n",
        "1. __Spot-profile your code.__ Use the `timeit` notebook magic to perform some basic profiling by cell or by line.\n",
        "1. __Profile your script comprehensively.__ The `cProfile` module has the ability to break down call by call to determine the number of calls and the total time spent on each.\n",
        "1. __Memory:__ You also saw `sys.getsizeof()` earlier, which you can use to check memory size of variables. Memory and performance are interrelated."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spot-check with `%%timeit`"
      ],
      "metadata": {
        "id": "FbgVHcXAXg2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We know that the first cell is much slower than the second."
      ],
      "metadata": {
        "id": "20Y5Z8A6A3lr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " `%timeit` is a form of _line magic_. Line magic arguments only extend to the end of the current line.\n",
        "\n",
        " `%%timeit` is a form of _cell magic_. It measures the execution time of the entire notebook cell.\n",
        "\n",
        " Two parameters to consider:\n",
        " - -n is the number of\n",
        " - -r is the repeats"
      ],
      "metadata": {
        "id": "oGY2BHZ0BqGu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In line mode you can time a single-line statement (though multiple\n",
        "ones can be chained with using semicolons).\n",
        "\n",
        "\n",
        "In cell mode, the statement in the first line is used as setup code\n",
        "(executed but not timed) and the body of the cell is timed.  The cell\n",
        "body has access to any variables created in the setup code."
      ],
      "metadata": {
        "id": "YAFizX9CBbgz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Profile with `cProfile`"
      ],
      "metadata": {
        "id": "WC9MI7cXXlBA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " But `%%timeit` isn't precise enough to tell which calls in each cell are taking the longest to execute."
      ],
      "metadata": {
        "id": "GMrkd59CAz9o"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiO9Nnk8ZLI9"
      },
      "source": [
        "## QA Workflow for Performance and Memory\n",
        "1. Spot-check for instances of unnecessary memory use\n",
        "1. Replace above instances with low-memory alternatives\n",
        "1. If necessary, create a sample to profile on: same complexity, smaller size. Then:\n",
        "1. Profile: Check for speed bottlenecks at a high level (%%timeit)\n",
        "1. Profile: For the slowest cell from prev step: check for speed bottlenecks at a granular level (cProfile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OWtmmQ5ZLI9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sUv2pKSZLI9"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV96G_TkZLI-"
      },
      "source": [
        "__Exercises summary__\n",
        "1. Replace lists with efficient alternatives\n",
        "    1. Storage: List to tuple\n",
        "    1. Look-up: List to set\n",
        "    1. Look-up: List to dictionary\n",
        "1. Replace sequences with efficient alternatives\n",
        "    1. Iteration: List comprehension to generator expression\n",
        "    1. Calculation: Loop to vector math\n",
        "1. Check for speed bottlenecks\n",
        "    1. Compare differences in speed with `timeit`\n",
        "    1. Check for speed bottlenecks in detail with `cProfile`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D-B-eEmZLI_"
      },
      "source": [
        "## 1. Replace lists with efficient alternatives"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Tuple-based storage"
      ],
      "metadata": {
        "id": "Ykg1mVcYVZuC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgHboiP5ZLI_"
      },
      "source": [
        "Scenario: You have CSVs stored in a subdirectory. Some of these CSVs can be converted to point shapefiles. For every CSV in the folder, you need to determine whether it contains a field called 'lat', which would indicate it has point coordinates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ho6G9kbEZLI_"
      },
      "outputs": [],
      "source": [
        "# Create list of file paths where the data is stored.\n",
        "myDataPaths = [filePath for file in directory]\n",
        "\n",
        "\n",
        "# Define a function for determining if a file meets your criteria.\n",
        "def meetsCriteria(filePaths):\n",
        "    \"\"\"\n",
        "    Dataframe must have a 'lat' field to be included.\n",
        "    \"\"\"\n",
        "    members = []\n",
        "    criterium = 'lat'\n",
        "\n",
        "    for filePath in filePaths:\n",
        "        with open(filePath) as fPath:\n",
        "            headerList = csv.DictReader(fPath).fieldnames\n",
        "            if criterium in headerList:\n",
        "                members.append(filePath)\n",
        "    return members\n",
        "\n",
        "\n",
        "# Print all matching file paths\n",
        "print(meetsCriteria(myDataPaths))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlHmpbBDZLJA"
      },
      "source": [
        "Change the filePaths list to a tuple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umxtX3qTZLJA"
      },
      "outputs": [],
      "source": [
        "# Exercise solution\n",
        "myDataPaths = (filePath for file in directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Set-based look-up"
      ],
      "metadata": {
        "id": "rSm-NycOy052"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below assigns a collection of placenames to a list. Then, it checks whether a placename is in the list. If not, the placename is reported missing.\n",
        "\n",
        "If you have 1 million placenames to look up and 6 names in the list, that’s up to 6 million checks."
      ],
      "metadata": {
        "id": "LQaHbpuyFyQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "placeNames_list = [\"Kinshasa\", \"Duluth\", \"Uruguay\", \"Doherty Residence\", \"Dinkytown\", \"Khazad-dum\"]\n",
        "\n",
        "# List look-up\n",
        "if \"Dinkytown\" not in placeNames_list:\n",
        "    print(\"Missing.\")  # O(n) look-up"
      ],
      "metadata": {
        "id": "3vq81k2CEoRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a different implementation that uses a faster-performing storage option for the collection."
      ],
      "metadata": {
        "id": "Uhr9kf53GY6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # # Exercise solution # # #\n",
        "\n",
        "placeNames_set = set(placeNames_list)\n",
        "\n",
        "# Set look-up\n",
        "if \"Dinkytown\" not in placeNames_set:\n",
        "    print(\"Missing.\")  # O(1) look-up"
      ],
      "metadata": {
        "id": "RS-8xOt3Erps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Change a list to a set, alternative example"
      ],
      "metadata": {
        "id": "tU0WItFEzwfI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing Duplicate Census Records by Household ID\n",
        "Problem:\n",
        "You’re cleaning a census dataset and want to remove duplicate household records based on a unique ID.\n",
        "\n",
        "First, we'll try using a List to Track Seen IDs (O(n) lookup each time):"
      ],
      "metadata": {
        "id": "gDo0CfpwzzIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seen_ids = []\n",
        "cleaned_data = []\n",
        "\n",
        "for record in census_data:\n",
        "    if record.household_id not in seen_ids:  # O(n) lookup\n",
        "        seen_ids.append(record.household_id)\n",
        "        cleaned_data.append(record)"
      ],
      "metadata": {
        "id": "5B0fl7e3z6iE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now,"
      ],
      "metadata": {
        "id": "y18QBTFRz_9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seen_ids = set()\n",
        "cleaned_data = []\n",
        "\n",
        "for record in census_data:\n",
        "    if record.household_id not in seen_ids:  # O(1) lookup\n",
        "        seen_ids.add(record.household_id)\n",
        "        cleaned_data.append(record)"
      ],
      "metadata": {
        "id": "7MIsIbkSz6Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe-uLcihZLJC"
      },
      "source": [
        "### 1.3 Dictionary-based look-up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfAqsBFnZLJC"
      },
      "source": [
        "Adapt the meetsCriteria function to add files to a set instead of appending to a list.\n",
        "<br><br>Actions:\n",
        "- Change the variable *members* to a set.\n",
        "- Modify the line *members.append(filePath)* to use the *.add()* function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkT1-X35ZLJN"
      },
      "outputs": [],
      "source": [
        "# Exercise solution\n",
        "def meetsCriteria(filePaths):\n",
        "    \"\"\"\n",
        "    Dataframe must have a 'lat' field to be included.\n",
        "    \"\"\"\n",
        "    members = {}\n",
        "    criterium = 'lat'\n",
        "\n",
        "    for filePath in filePaths:\n",
        "        with open(filePath) as fPath:\n",
        "            headerList = csv.DictReader(fPath).fieldnames\n",
        "            if headerList.intersection(criterium) is not None:\n",
        "                members.add(filePath)\n",
        "    return members"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Replace sequences with efficient alternatives"
      ],
      "metadata": {
        "id": "rfYFgIiJW1yA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Generator expression"
      ],
      "metadata": {
        "id": "l9xzVCANWcC6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Vector math"
      ],
      "metadata": {
        "id": "UvNRut3rWfPk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Check for speed bottlenecks"
      ],
      "metadata": {
        "id": "n2N4_JqzUqL4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkfkhHtBZLJN"
      },
      "source": [
        "### 2.1 Compare differences in speed using `timeit`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN57nQonZLJO"
      },
      "source": [
        "Using `%%timeit`, compare the time it took to create myDataPaths as a list (original code) versus as a tuple (exercise solution)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4maIX64mZLJO"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "print([filePath for file in directory])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1m7iEWTZLJP"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "## Your solution here ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBPP5scfZLJP"
      },
      "source": [
        "Use `%%timeit` again to compare list-based lookup to set intersection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEPxsZ0fZLJP"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "def meetsCriteria(filePaths):\n",
        "    \"\"\"\n",
        "    Dataframe must have a 'lat' field to be included.\n",
        "    \"\"\"\n",
        "    members = []\n",
        "    criterium = 'lat'\n",
        "\n",
        "    for filePath in filePaths:\n",
        "        with open(filePath) as fPath:\n",
        "            headerList = csv.DictReader(fPath).fieldnames\n",
        "            if criterium in headerList:\n",
        "                members.append(filePath)\n",
        "    return members\n",
        "\n",
        "\n",
        "# Print all matching file paths\n",
        "print(meetsCriteria(myDataPaths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6L0PleqtZLJQ"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "## Your solution here ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJn4y8mLZLJQ"
      },
      "source": [
        "Finally, compare the second list vs. set change that you made."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4Vxyvf0ZLJQ"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "def meetsCriteria(filePaths):\n",
        "    \"\"\"\n",
        "    Dataframe must have a 'lat' field to be included.\n",
        "    \"\"\"\n",
        "    members = []\n",
        "    criterium = 'lat'\n",
        "\n",
        "    for filePath in filePaths:\n",
        "        with open(filePath) as fPath:\n",
        "            headerList = csv.DictReader(fPath).fieldnames\n",
        "            if criterium in headerList:\n",
        "                members.append(filePath)\n",
        "    return members\n",
        "\n",
        "\n",
        "# Print all matching file paths\n",
        "print(meetsCriteria(myDataPaths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnEhPSJ1ZLJQ"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "## Your solution here ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyY72o5RZLJS"
      },
      "source": [
        "### 3.1 Check for speed bottlenecks in detail using `cProfile`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvkCZLEeZLJS"
      },
      "source": [
        "Use cProfile to locate the slowest calls in your improved script.\n",
        "\n",
        "Hint: Sort by tottime instead of name to find hotspots more easily."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQKz2fJFZLJT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ArcGISPro",
      "language": "Python",
      "name": "python3"
    },
    "language_info": {
      "file_extension": ".py",
      "name": "python",
      "version": "3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}