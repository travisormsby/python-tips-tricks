{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-_2hR6yZLIl"
      },
      "source": [
        "# Performance and Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VogyfkL7ZLIq"
      },
      "source": [
        "When you begin to use Python regularly in your work, you'll start noticing bottlenecks in your code. Some workflows may run at lightning speed, while others take hours of processing time to complete, or even crash.\n",
        "\n",
        "Avoiding bloat is invaluable as you move toward using code for automation, bigger data, and working with APIs. Code efficiency means:\n",
        "- Less chance of a slowdown or crash: the dreaded MemoryError.\n",
        "- Quicker response time and fewer bottlenecks for the larger workflow.\n",
        "- Better scaling.\n",
        "- Efficient code is often (but not always!) cleaner and more readable.\n",
        "\n",
        "Let's look at some ways you can reduce bloat in your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2BFe18pZLIr"
      },
      "source": [
        "## Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_P41638ZLIw"
      },
      "source": [
        "tl;dr\n",
        "<br>Access and store only what you need, no more.\n",
        "- __Storage__: avoid a list where you could use a tuple\n",
        "- __Membership look-up__: avoid a list where you could use a set or dictionary\n",
        "- __Iteration__: avoid a sequence where you could use generator\n",
        "- __Calculation__: avoid a loop where you could use vectorized math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "Yu9yyeYPZLIx"
      },
      "source": [
        "### Storage: lists vs. tuples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "IqMfe4DUZLIx"
      },
      "source": [
        "If you have a collection of values, your first thought may be to store them in a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "hidden": true,
        "id": "oVG7ozejZLIy"
      },
      "outputs": [],
      "source": [
        "data_list = [17999712, 2015, 'Hawkins Road', 'Linden ', 'NC', 28356]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "vPGEfGsKZLIz"
      },
      "source": [
        "Lists are nice because they are very flexible. You can change the values in the list, including appending and removing values. But that flexibility comes at a cost. Lists are less efficient than tuples. For example, they use more memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "hidden": true,
        "id": "kzw4GFpYZLI1",
        "outputId": "e0138832-159c-4fed-9f17-69e93ebd8899",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "104\n",
            "88\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "data_tuple = (17999712, 2015, 'Hawkins Road', 'Linden ', 'NC', 28356)\n",
        "\n",
        "print(sys.getsizeof(data_list))\n",
        "print(sys.getsizeof(data_tuple))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "SncGVcIiZLI3"
      },
      "source": [
        "If you aren't going to be changing the values in a collection, use a tuple instead of a list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "YdLJhldrZLI3"
      },
      "source": [
        "### Membership look-up: lists vs. sets and dictionaries"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, when you want to see if an element _already exists_ in a collection of elements, use a set or dictionary to store that collection if possible.\n",
        "\n",
        "Lists and tuples require **sequential look-up** to see if an element is a member of the collection. That means that on average, they have to make n/2 comparisons for a collection of length n. Meanwhile, hash tables and dictionaries **map keys to values**. That means no matter how big the collection is, the set only ever has to check 1 value.\n",
        "\n",
        "Fun fact: A set can use a hash table for look-ups, similar to a dictionary, because every element in a set is unique."
      ],
      "metadata": {
        "id": "x9vIWqKJESyn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- List and tuple look-up goes at the speed of _O(n): linear time_. Time increases linearly with the number of elements.\n",
        "    - With lists, Python scans the entire list until it finds the match (or reaches the end).\n",
        "    - Worst case: it has to look at every element.\n",
        "\n",
        "- Set and dictionary look-up goes at the speed of _O(1): constant time_. Takes the same time no matter the size of the data.\n",
        "    - Sets are built on hash tables. Python computes the hash of the element and jumps straight to where it should be stored."
      ],
      "metadata": {
        "id": "0VCAv3ZUxOXY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "oVdOgTk1ZLI4"
      },
      "source": [
        "The example below shows that a set is over 1000x faster than a list in calculating the first 100,000 values of [Recaman's sequence](https://oeis.org/search?q=recaman&language=english&go=Search) but the concept applies any time you are checking for membership in a large collection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "hidden": true,
        "id": "WpTGEYfyZLI5"
      },
      "outputs": [],
      "source": [
        "def recaman_check(cur, i, visited):\n",
        "    return (cur - i) < 0 or (cur - i) in visited\n",
        "\n",
        "def recaman_list(n: int) -> list[int]:\n",
        "    \"\"\"\n",
        "    return a list of the first n numbers of the Recaman series\n",
        "    \"\"\"\n",
        "\n",
        "    visited_list = [0]\n",
        "    current = 0\n",
        "    for i in range(1, n):\n",
        "        if recaman_check(current, i, visited_list):\n",
        "            current += i\n",
        "        else:\n",
        "            current -= i\n",
        "        visited_list.append(current)\n",
        "    return visited_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "hidden": true,
        "id": "nZDnh3iWZLI6",
        "outputId": "abbebfc7-0557-46f3-dc5f-a3ae2ee46830",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33.6 s ± 1.62 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "recaman_list(100000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "hidden": true,
        "id": "vvLVZGkKZLI6"
      },
      "outputs": [],
      "source": [
        "def recaman_set(n: int) -> list[int]:\n",
        "    visited_set = {0}\n",
        "    current = 0\n",
        "    for i in range(1, 100_000):\n",
        "        if recaman_check(current, i, visited_set):\n",
        "            current += i\n",
        "        else:\n",
        "            current -= i\n",
        "        visited_set.add(current)\n",
        "    return visited_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "hidden": true,
        "id": "wFaIMHJlZLI7",
        "outputId": "ca3f5f2d-1a70-428e-a8ba-90ab4015b9b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23.7 ms ± 1.15 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "recaman_set(100000)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you add an element to a set, 1) Python calls the element’s __hash__() method to get a hash value (an integer); 2) That hash value determines where the element will be stored in the set's internal structure; 3) When checking if an element is in the set, Python uses the hash to quickly find it.\n",
        "\n",
        "Note: Lists perform faster than sets for ordered operations (think: sorting)."
      ],
      "metadata": {
        "id": "cmwf-LTNLk2o"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "da9ChQAwZLI7"
      },
      "source": [
        "### Iteration: sequences vs. generators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "AES7kqT2ZLI8"
      },
      "source": [
        "Regular functions and comprehensions typically create a container type like a list or a dictionary to store the data that results from the function’s intended computation. All this data is stored in memory at the same time.\n",
        "\n",
        "In contrast, iterators keep only one data item in memory at a time, generating the next items on demand or lazily.\n",
        "\n",
        "With iterators and generators, you don’t need to store all the data in your compter’s memory at the same time.\n",
        "\n",
        "Iterators and generators also allow you to completely decouple iteration from processing individual items. They let you connect multiple data processing stages to create memory-efficient data processing pipelines."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When working with dataframes, we often use functions to operate on data, but generators can be more memory-efficient and faster for certain tasks—especially when you're processing rows one at a time or streaming large datasets."
      ],
      "metadata": {
        "id": "59BbxRiDuYVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s say you have a huge CSV that you want to process row by row, applying some logic to each row. Using a generator here helps avoid loading the entire DataFrame into memory."
      ],
      "metadata": {
        "id": "td-sjAbZuk_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def process_all_rows(filepath):\n",
        "    df = pd.read_csv(filepath)\n",
        "    for _, row in df.iterrows():\n",
        "        process_row(row)\n",
        "\n",
        "def process_row(row):\n",
        "    # Imagine some expensive operation here\n",
        "    if row[\"value\"] > 1000:\n",
        "        print(row[\"name\"], row[\"value\"])"
      ],
      "metadata": {
        "id": "vi6duXe_ujwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the CSV is huge, this can eat up memory. Instead, what if we process data in chunks or rows lazily?"
      ],
      "metadata": {
        "id": "w06e15kmuppV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def row_generator(filepath, chunksize=1000):\n",
        "    for chunk in pd.read_csv(filepath, chunksize=chunksize):\n",
        "        for _, row in chunk.iterrows():\n",
        "            yield row\n",
        "\n",
        "def process_large_file(filepath):\n",
        "    for row in row_generator(filepath):\n",
        "        if row[\"value\"] > 1000:\n",
        "            print(row[\"name\"], row[\"value\"])"
      ],
      "metadata": {
        "id": "chy2TtgYuzUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When to prefer a generator:\n",
        "- You're dealing with very large datasets that would be cumbersome to load into memory.\n",
        "- You want to start processing before loading everything.\n",
        "- You're doing line-by-line processing, not vectorized Pandas ops.\n",
        "- Streaming data or preprocessing before database insertions."
      ],
      "metadata": {
        "id": "xgvGsS52u4G6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculation: loop versus intersection"
      ],
      "metadata": {
        "id": "0vGWLh-mBnAY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HhMLyvGZLI8"
      },
      "source": [
        "## Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vwEgO0TZLI8"
      },
      "source": [
        "tl;dr\n",
        "<br>Make time for performance checks.\n",
        "\n",
        "Resources:\n",
        "1. __Spot-profile your code.__ Use the `timeit` notebook magic to perform some basic profiling by cell or by line.\n",
        "1. __Profile your script comprehensively.__ The `cProfile` module has the ability to break down call by call to determine the number of calls and the total time spent on each.\n",
        "1. __Memory:__ You also saw `sys.getsizeof()` earlier, which you can use to check memory size of variables. Memory and performance are interrelated."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spot-check with `%%timeit`"
      ],
      "metadata": {
        "id": "FbgVHcXAXg2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We know that the first cell is much slower than the second."
      ],
      "metadata": {
        "id": "20Y5Z8A6A3lr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " `%timeit` is a form of _line magic_. Line magic arguments only extend to the end of the current line.\n",
        "\n",
        " `%%timeit` is a form of _cell magic_. It measures the execution time of the entire notebook cell.\n",
        "\n",
        " Two parameters to consider:\n",
        " - -n is the number of\n",
        " - -r is the repeats"
      ],
      "metadata": {
        "id": "oGY2BHZ0BqGu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In line mode you can time a single-line statement (though multiple\n",
        "ones can be chained with using semicolons).\n",
        "\n",
        "\n",
        "In cell mode, the statement in the first line is used as setup code\n",
        "(executed but not timed) and the body of the cell is timed.  The cell\n",
        "body has access to any variables created in the setup code."
      ],
      "metadata": {
        "id": "YAFizX9CBbgz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Profile with `cProfile`"
      ],
      "metadata": {
        "id": "WC9MI7cXXlBA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " But `%%timeit` isn't precise enough to tell which calls in each cell are taking the longest to execute."
      ],
      "metadata": {
        "id": "GMrkd59CAz9o"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiO9Nnk8ZLI9"
      },
      "source": [
        "## QA Workflow for Performance and Memory\n",
        "1. Spot-check for instances of unnecessary memory use\n",
        "1. Replace above instances with low-memory alternatives\n",
        "1. If necessary, create a sample to profile on: same complexity, smaller size. Then:\n",
        "1. Profile: Check for speed bottlenecks at a high level (%%timeit)\n",
        "1. Profile: For the slowest cell from prev step: check for speed bottlenecks at a granular level (cProfile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OWtmmQ5ZLI9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sUv2pKSZLI9"
      },
      "source": [
        "# Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV96G_TkZLI-"
      },
      "source": [
        "__Exercise steps:__\n",
        "1. Replace lists with memory-saving alternatives\n",
        "    1. Replace with tuple\n",
        "    1. Replace with set\n",
        "    1. Replace with set (2nd example)\n",
        "    1. Compare differences in speed with `%%timeit`\n",
        "1. Replace sequences with memory-saving alternatives\n",
        "    1. Convert list comprehension to generator expression\n",
        "    1. Convert loop to intersection\n",
        "    1. Compare differences in speed with `%%timeit`\n",
        "1. Check for speed bottlenecks in detail with `cProfile`\n",
        "    1. Apply for all the above code blocks\n",
        "    1. Inspect results\n",
        "1. Challenge: Improve readability across the script"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UItHlPjbZLI-"
      },
      "source": [
        "## 0) Prepare workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOJQSfB3ZLI-"
      },
      "outputs": [],
      "source": [
        "import csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D-B-eEmZLI_"
      },
      "source": [
        "## 1) Replace lists [ ] with memory-saving alternatives (tuple, set, and dictionary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgHboiP5ZLI_"
      },
      "source": [
        "Scenario: You have CSVs stored in a subdirectory. Some of these CSVs can be converted to point shapefiles. For every CSV in the folder, you need to determine whether it contains a field called 'lat', which would indicate it has point coordinates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ho6G9kbEZLI_"
      },
      "outputs": [],
      "source": [
        "# Create list of file paths where the data is stored.\n",
        "myDataPaths = [filePath for file in directory]\n",
        "\n",
        "\n",
        "# Define a function for determining if a file meets your criteria.\n",
        "def meetsCriteria(filePaths):\n",
        "    \"\"\"\n",
        "    Dataframe must have a 'lat' field to be included.\n",
        "    \"\"\"\n",
        "    members = []\n",
        "    criterium = 'lat'\n",
        "\n",
        "    for filePath in filePaths:\n",
        "        with open(filePath) as fPath:\n",
        "            headerList = csv.DictReader(fPath).fieldnames\n",
        "            if criterium in headerList:\n",
        "                members.append(filePath)\n",
        "    return members\n",
        "\n",
        "\n",
        "# Print all matching file paths\n",
        "print(meetsCriteria(myDataPaths))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfUXR2j3ZLJA"
      },
      "source": [
        "### Change a list to a tuple: Reducing storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlHmpbBDZLJA"
      },
      "source": [
        "Change the filePaths list to a tuple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umxtX3qTZLJA"
      },
      "outputs": [],
      "source": [
        "# Exercise solution\n",
        "myDataPaths = (filePath for file in directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Change a list to a set: Membership lookup"
      ],
      "metadata": {
        "id": "rSm-NycOy052"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below assigns a collection of placenames to a list. Then, it checks whether a placename is in the list. If not, it is reported missing.\n",
        "\n",
        "If you have 1 million placenames to look up and 6 names in the list, that’s up to 6 million checks."
      ],
      "metadata": {
        "id": "LQaHbpuyFyQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "placeNames_list = [\"Kinshasa\", \"Duluth\", \"Uruguay\", \"Doherty Residence\", \"Dinkytown\", \"Khazad-dum\"]\n",
        "\n",
        "# List look-up\n",
        "if \"Dinkytown\" not in placeNames_list:\n",
        "    print(\"Missing.\")  # O(n) look-up"
      ],
      "metadata": {
        "id": "3vq81k2CEoRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a different implementation that uses a faster-performing storage option for the collection."
      ],
      "metadata": {
        "id": "Uhr9kf53GY6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # # Exercise solution # # #\n",
        "\n",
        "placeNames_set = set(placeNames_list)\n",
        "\n",
        "# Set look-up\n",
        "if \"Dinkytown\" not in placeNames_set:\n",
        "    print(\"Missing.\")  # O(1) look-up"
      ],
      "metadata": {
        "id": "RS-8xOt3Erps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Change a list to a set, alternative example"
      ],
      "metadata": {
        "id": "tU0WItFEzwfI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing Duplicate Census Records by Household ID\n",
        "Problem:\n",
        "You’re cleaning a census dataset and want to remove duplicate household records based on a unique ID.\n",
        "\n",
        "First, we'll try using a List to Track Seen IDs (O(n) lookup each time):"
      ],
      "metadata": {
        "id": "gDo0CfpwzzIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seen_ids = []\n",
        "cleaned_data = []\n",
        "\n",
        "for record in census_data:\n",
        "    if record.household_id not in seen_ids:  # O(n) lookup\n",
        "        seen_ids.append(record.household_id)\n",
        "        cleaned_data.append(record)"
      ],
      "metadata": {
        "id": "5B0fl7e3z6iE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now,"
      ],
      "metadata": {
        "id": "y18QBTFRz_9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seen_ids = set()\n",
        "cleaned_data = []\n",
        "\n",
        "for record in census_data:\n",
        "    if record.household_id not in seen_ids:  # O(1) lookup\n",
        "        seen_ids.add(record.household_id)\n",
        "        cleaned_data.append(record)"
      ],
      "metadata": {
        "id": "7MIsIbkSz6Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe-uLcihZLJC"
      },
      "source": [
        "### Change list to a dictionary: Accessing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfAqsBFnZLJC"
      },
      "source": [
        "Adapt the meetsCriteria function to add files to a set instead of appending to a list.\n",
        "<br><br>Actions:\n",
        "- Change the variable *members* to a set.\n",
        "- Modify the line *members.append(filePath)* to use the *.add()* function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkT1-X35ZLJN"
      },
      "outputs": [],
      "source": [
        "# Exercise solution\n",
        "def meetsCriteria(filePaths):\n",
        "    \"\"\"\n",
        "    Dataframe must have a 'lat' field to be included.\n",
        "    \"\"\"\n",
        "    members = {}\n",
        "    criterium = 'lat'\n",
        "\n",
        "    for filePath in filePaths:\n",
        "        with open(filePath) as fPath:\n",
        "            headerList = csv.DictReader(fPath).fieldnames\n",
        "            if headerList.intersection(criterium) is not None:\n",
        "                members.add(filePath)\n",
        "    return members"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkfkhHtBZLJN"
      },
      "source": [
        "### Compare differences in speed using `%%timeit`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN57nQonZLJO"
      },
      "source": [
        "Using `%%timeit`, compare the time it took to create myDataPaths as a list (original code) versus as a tuple (exercise solution)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4maIX64mZLJO"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "print([filePath for file in directory])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1m7iEWTZLJP"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "## Your solution here ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBPP5scfZLJP"
      },
      "source": [
        "Use `%%timeit` again to compare list-based lookup to set intersection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEPxsZ0fZLJP"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "def meetsCriteria(filePaths):\n",
        "    \"\"\"\n",
        "    Dataframe must have a 'lat' field to be included.\n",
        "    \"\"\"\n",
        "    members = []\n",
        "    criterium = 'lat'\n",
        "\n",
        "    for filePath in filePaths:\n",
        "        with open(filePath) as fPath:\n",
        "            headerList = csv.DictReader(fPath).fieldnames\n",
        "            if criterium in headerList:\n",
        "                members.append(filePath)\n",
        "    return members\n",
        "\n",
        "\n",
        "# Print all matching file paths\n",
        "print(meetsCriteria(myDataPaths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6L0PleqtZLJQ"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "## Your solution here ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJn4y8mLZLJQ"
      },
      "source": [
        "Finally, compare the second list vs. set change that you made."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4Vxyvf0ZLJQ"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "def meetsCriteria(filePaths):\n",
        "    \"\"\"\n",
        "    Dataframe must have a 'lat' field to be included.\n",
        "    \"\"\"\n",
        "    members = []\n",
        "    criterium = 'lat'\n",
        "\n",
        "    for filePath in filePaths:\n",
        "        with open(filePath) as fPath:\n",
        "            headerList = csv.DictReader(fPath).fieldnames\n",
        "            if criterium in headerList:\n",
        "                members.append(filePath)\n",
        "    return members\n",
        "\n",
        "\n",
        "# Print all matching file paths\n",
        "print(meetsCriteria(myDataPaths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnEhPSJ1ZLJQ"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "## Your solution here ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TKfRdYTZLJR"
      },
      "source": [
        "## 2) Replace sequences with memory-saving alternatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjcAcqnqZLJR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbm03358ZLJR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzWzDM0DZLJR"
      },
      "source": [
        "## 3) Check for speed bottlenecks in detail"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyY72o5RZLJS"
      },
      "source": [
        "### Use cProfile to locate the slowest calls in the original script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcMcb9K0ZLJS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8aJmibAZLJS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvkCZLEeZLJS"
      },
      "source": [
        "### Use cProfile to locate the slowest calls in your improved script.\n",
        "Hint: Sort by tottime instead of name to find hotspots more easily."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxacUnfRZLJT"
      },
      "source": [
        "Solution from the previous steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0qyhllOZLJT"
      },
      "outputs": [],
      "source": [
        "# Create list of file paths where the data is stored.\n",
        "myDataPaths = (filePath for file in directory)\n",
        "\n",
        "\n",
        "# Define a function for determining if a file meets your criteria.\n",
        "def meetsCriteria(filePaths):\n",
        "    \"\"\"\n",
        "    Dataframe must have a 'lat' field to be included.\n",
        "    \"\"\"\n",
        "    members = {}\n",
        "    criterium = 'lat'\n",
        "\n",
        "    for filePath in filePaths:\n",
        "        with open(filePath) as fPath:\n",
        "            headerList = csv.DictReader(fPath).fieldnames\n",
        "            if headerList.intersection(criterium) is not None:\n",
        "                members.add(filePath)\n",
        "    return members\n",
        "\n",
        "\n",
        "# Print all matching file paths\n",
        "print(meetsCriteria(myDataPaths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQKz2fJFZLJT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEx9_Y1yZLJU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WN64y56kZLJU"
      },
      "source": [
        "## 4) Challenge: Improve readability across the script"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyPXC__UZLJU"
      },
      "source": [
        "For the function *meetsCriteria()*, add more detail in the doc string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dael9UmOZLJU"
      },
      "outputs": [],
      "source": [
        "## Your solution here ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lPKy-VMZLJV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTkDomm7ZLJV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5VIEvheZLJV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieCSrwdCZLJV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAKP2u_dZLJV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bl1c4tzlZLJW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLhNXKqDZLJW"
      },
      "source": [
        "# Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3IgNHJ-ZLJW"
      },
      "source": [
        "Imagine you have a database (geopackage) of a city's building footprint geometries. Each layer represents the new construction built in that year. What you need instead, however, is a snapshot of total built area each year: all of that year's construction plus anything existing from previous years in the study.\n",
        "\n",
        "To create this new database, for every year in the study, you will subset building features for that year and all previous years, dissolve them to create one cumulative feature, and then save to file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7s_C0ZRZLJW"
      },
      "outputs": [],
      "source": [
        "ftPrints = gpd.read_file(\"City.gpkg\", layer=\"Footprints\")\n",
        "constructYears = [1999, 2000, 2001, 2002, 2003, 2004]\n",
        "startYear = 1999\n",
        "print('Prepared to dissolve building footprints for cumulative years from 1999 to 2004.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axD87Iw8ZLJX"
      },
      "source": [
        "#### BEFORE: for loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wdDphFAZLJX"
      },
      "source": [
        "One way to perform this workflow is with a for loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USJw4YfDZLJX"
      },
      "outputs": [],
      "source": [
        "for year in constructYears:\n",
        "    timeframe = ftPrints[ftPrints['year'].between(startYear, year, inclusive=True)]\n",
        "    tfDissolve = timeframe.dissolve(by='ID',\n",
        "                                      aggfunc={\"year\": \"max\"},\n",
        "                                      as_index=False)\n",
        "\n",
        "    yearName = ''.join(['cu', str(year)])\n",
        "    tfDissolve.to_file(driver='GPKG', filename='cuFootprints.gpkg', layer=yearName)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzAXHAEWZLJY"
      },
      "source": [
        "#### AFTER: generator\n",
        "*(exercise solution)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RPr1J39ZLJY"
      },
      "source": [
        "You can improve this code by creating a data pipeline of generator expressions, ending in a for loop for only the final step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWUlWTKuZLJY"
      },
      "outputs": [],
      "source": [
        "# First generator\n",
        "timeframes = (ftPrints[ftPrints['year'].between(startYear, year, inclusive=True)] for year in constructYears)\n",
        "\n",
        "# Second generator\n",
        "tfDissolve = (timeframe.dissolve(by='ID', aggfunc={\"year\": \"max\"}, as_index=False) for timeframe in timeframes)\n",
        "\n",
        "# Third generator\n",
        "yearName = (''.join(['cu', str(year)]) for year in constructYears)\n",
        "\n",
        "# Commence iteration\n",
        "for year in constructYears:\n",
        "    tfDissolve.to_file(driver='GPKG', filename='cuFootprints.gpkg', layer=yearName)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "FkAYYOkhZLJY"
      },
      "source": [
        "## Profile your code instead of guessing about performance bottlenecks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PnfsVFtZLJZ"
      },
      "outputs": [],
      "source": [
        "def recaman_check(cur, i, visited):\n",
        "    return (cur - i) < 0 or (cur - i) in visited\n",
        "\n",
        "def recaman_list(n: int) -> list[int]:\n",
        "    \"\"\"\n",
        "    return a list of the first n numbers of the Recaman series\n",
        "    \"\"\"\n",
        "\n",
        "    visited_list = [0]\n",
        "    current = 0\n",
        "    for i in range(1, n):\n",
        "        if recaman_check(current, i, visited_list):\n",
        "            current += i\n",
        "        else:\n",
        "            current -= i\n",
        "        visited_list.append(current)\n",
        "    return visited_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1pCAPs2ZLJZ",
        "outputId": "285d5cbd-aaa1-4c38-9bbd-5ade3ce996ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19.2 s ± 20.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "recaman_list(100000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6LIwdrLZLJa"
      },
      "outputs": [],
      "source": [
        "def recaman_set(n: int) -> list[int]:\n",
        "    visited_set = {0}\n",
        "    current = 0\n",
        "    for i in range(1, 100_000):\n",
        "        if recaman_check(current, i, visited_set):\n",
        "            current += i\n",
        "        else:\n",
        "            current -= i\n",
        "        visited_set.add(current)\n",
        "    return visited_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_P2nONvZLJa",
        "outputId": "ea9f7c50-8102-4bb9-a69c-b34548742b15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15.1 ms ± 94.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "recaman_set(100000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EE2jhFjZLJb"
      },
      "source": [
        "The example above uses the `%%timeit` notebook magic to perform some basic profiling. We know that the first cell is much slower than the second. But `%%timeit` isn't precise enough to tell which calls in each cell are taking the longest to execute. Are sets faster because it's easier to check if an element is in a set? Or are sets faster because it is easier to add an element to a set than append an element to a list?\n",
        "\n",
        "The `cProfile` module has the ability to break down call by call to determine the number of calls and the total time spent on each. Running each function with cProfile demonstrates that the in the list version of the function, the time to append elements is dwarfed by the time it takes to check if an element is in a list. The set version of the function is actually a little slower to add elements, but it is much faster to check elements for membership."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwlpNXGKZLJb",
        "outputId": "49684c4b-dade-4dba-cbc6-277066a490d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         200002 function calls in 19.888 seconds\n",
            "\n",
            "   Ordered by: standard name\n",
            "\n",
            "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
            "    99999   19.808    0.000   19.808    0.000 1555087545.py:1(recaman_check)\n",
            "        1    0.072    0.072   19.888   19.888 1555087545.py:4(recaman_list)\n",
            "        1    0.001    0.001   19.888   19.888 <string>:1(<module>)\n",
            "        1    0.000    0.000   19.888   19.888 {built-in method builtins.exec}\n",
            "    99999    0.007    0.000    0.007    0.000 {method 'append' of 'list' objects}\n",
            "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import cProfile\n",
        "\n",
        "cProfile.run('recaman_list(100000)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "8uQp8sowZLJb",
        "outputId": "37700dd3-1850-4103-8abf-c1b5bbd1c765"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         200002 function calls in 0.068 seconds\n",
            "\n",
            "   Ordered by: standard name\n",
            "\n",
            "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
            "    99999    0.018    0.000    0.018    0.000 1555087545.py:1(recaman_check)\n",
            "        1    0.041    0.041    0.068    0.068 662776923.py:1(recaman_set)\n",
            "        1    0.001    0.001    0.068    0.068 <string>:1(<module>)\n",
            "        1    0.000    0.000    0.068    0.068 {built-in method builtins.exec}\n",
            "    99999    0.009    0.000    0.009    0.000 {method 'add' of 'set' objects}\n",
            "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cProfile.run('recaman_set(100000)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d51TTwwIZLJc"
      },
      "source": [
        "## Use more tuples and fewer lists\n",
        "If you have a collection of values, your first thought may be to store them in a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRrFIeq6ZLJc"
      },
      "outputs": [],
      "source": [
        "data_list = [17999712, 2015, 'Hawkins Road', 'Linden ', 'NC', 28356]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7ejqLFLZLJc"
      },
      "source": [
        "Lists are nice because they are very flexible. You can change the values in the list, including appending and removing values. But that flexibility comes at a cost. Lists are less efficient than tuples. For example, they use more memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcpZGs6WZLJd"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "data_tuple = (17999712, 2015, 'Hawkins Road', 'Linden ', 'NC', 28356)\n",
        "\n",
        "print(sys.getsizeof(data_list))\n",
        "print(sys.getsizeof(data_tuple))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHcHoVlUZLJd"
      },
      "source": [
        "If you aren't going to be changing the values in a collection, use a tuple instead of a list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "Nt_YyzRAZLJd"
      },
      "source": [
        "## Use more iterators and fewer lists/tuples for loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuURToHRZLJd"
      },
      "source": [
        "Regardless of whether you use a list or a tuple, you need to store a reference to every value in memory. Both lists and tuples take up more memory the bigger they get."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtWMy9ouZLJe",
        "outputId": "5c20c0f9-5767-4d8f-8d64-1c09eedcfe98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "120\n",
            "80040\n"
          ]
        }
      ],
      "source": [
        "little_tuple = tuple(range(10))\n",
        "big_tuple = tuple(range(10000))\n",
        "\n",
        "print(sys.getsizeof(little_tuple))\n",
        "print(sys.getsizeof(big_tuple))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZB0uGxyZLJe"
      },
      "source": [
        "Lists and tuples are iterables because you can iterate over their values. Iterators are a special type of iterable that evaluate their values lazily, only when the values are needed. They don't hold references to all the values in memory. That means iterators have constant size in memory. For example, `enumerate` produces an iterator. ArcPy cursors also produce iterators (not shown here so that this notebook works in an standard Notebook Server environment without access to ArcPy)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Y0V6BjrZLJe",
        "outputId": "686b1036-378c-4d0e-9e14-7acd36b83dae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "72\n",
            "72\n"
          ]
        }
      ],
      "source": [
        "from collections.abc import Iterator\n",
        "\n",
        "little_tuple_iterator = enumerate(little_tuple)\n",
        "big_tuple_iterator = enumerate(big_tuple)\n",
        "\n",
        "print(isinstance(little_tuple_iterator, Iterator))\n",
        "print(sys.getsizeof(little_tuple_iterator))\n",
        "print(sys.getsizeof(big_tuple_iterator))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAH80jJGZLJf"
      },
      "source": [
        "An iterator is any object that implements both the `__iter__` and `__next__` methods. You can make your own iterators by creating a custom class that implements those methods (or a class that inherits from `collections.abc.Iterator`). An easier way to create your own iterators is to create a special type of iterator called a generator. Generators are functions that use a `yield` statement to produce values lazily, one at a time (instead of all at once like a list or tuple). For example, you could use a generator to produce infinite sequential ObjectID numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHxQGYkvZLJf",
        "outputId": "0865d81b-7c1b-4b33-b79b-1ac142de11d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is oid a generator? True\n",
            "Is oid an iterator? True\n",
            "At first the size of oid is 192 bytes\n",
            "The first value produced by oid is 1000\n",
            "After 10,000 iterations, the next value produced by oid is 11001\n",
            "After 10,000 iterations, the size of oid is 192 bytes\n"
          ]
        }
      ],
      "source": [
        "from types import GeneratorType\n",
        "\n",
        "def make_oids(start):\n",
        "    while True:\n",
        "        yield start\n",
        "        start += 1\n",
        "\n",
        "oid = make_oids(start=1000)\n",
        "\n",
        "is_generator = isinstance(oid, GeneratorType)\n",
        "is_iterator = isinstance(oid, Iterator)\n",
        "print(f\"Is oid a generator? {is_generator}\")\n",
        "print(f\"Is oid an iterator? {is_iterator}\")\n",
        "\n",
        "# Every time you want a new oid, just call next(oid). The size of oid never changes\n",
        "print(f\"At first the size of oid is {sys.getsizeof(oid)} bytes\")\n",
        "print(f\"The first value produced by oid is {next(oid)}\")\n",
        "\n",
        "for i in range(10000):\n",
        "    new_oid = next(oid)\n",
        "\n",
        "print(f\"After 10,000 iterations, the next value produced by oid is {next(oid)}\")\n",
        "print(f\"After 10,000 iterations, the size of oid is {sys.getsizeof(oid)} bytes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewcr0PsOZLJg"
      },
      "source": [
        "Iterators (inlcuding generators) are useful for enabling better separation of concerns. Maybe you need to create many records and assign each of them an ObjectID. You could do that in a loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nn4PuPCZLJg",
        "outputId": "eae4a9be-6845-4f3d-a65a-3dfd3d4f74d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'OID': 1000, 'value': 0},\n",
              " {'OID': 1001, 'value': 1},\n",
              " {'OID': 1002, 'value': 2},\n",
              " {'OID': 1003, 'value': 3},\n",
              " {'OID': 1004, 'value': 4},\n",
              " {'OID': 1005, 'value': 5},\n",
              " {'OID': 1006, 'value': 6},\n",
              " {'OID': 1007, 'value': 7},\n",
              " {'OID': 1008, 'value': 8},\n",
              " {'OID': 1009, 'value': 9}]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "records = []\n",
        "oid = 1000\n",
        "for value in range(10):\n",
        "    record = {\n",
        "        'OID':  oid,\n",
        "        'value': value,\n",
        "    }\n",
        "    oid += 1\n",
        "    records.append(record)\n",
        "records"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-fxlHvGZLJg"
      },
      "source": [
        "That works, but the loop is doing two things: making a record and making an OID value. It would be better if those things were separated. That way if we later need to change the way OID values are generated, we don't have to change the code in the loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIRlXYPNZLJg",
        "outputId": "b7eeac9c-f154-402f-86d8-7ed01171db22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'OID': 1000, 'value': 0},\n",
              " {'OID': 1001, 'value': 1},\n",
              " {'OID': 1002, 'value': 2},\n",
              " {'OID': 1003, 'value': 3},\n",
              " {'OID': 1004, 'value': 4},\n",
              " {'OID': 1005, 'value': 5},\n",
              " {'OID': 1006, 'value': 6},\n",
              " {'OID': 1007, 'value': 7},\n",
              " {'OID': 1008, 'value': 8},\n",
              " {'OID': 1009, 'value': 9}]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "records = []\n",
        "oid = make_oids(1000)\n",
        "for value in range(10):\n",
        "    record = {\n",
        "        'OID':  next(oid),\n",
        "        'value': value,\n",
        "    }\n",
        "    records.append(record)\n",
        "records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ameEkRclZLJh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ArcGISPro",
      "language": "Python",
      "name": "python3"
    },
    "language_info": {
      "file_extension": ".py",
      "name": "python",
      "version": "3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}